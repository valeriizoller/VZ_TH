{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(r\"C:\\Users\\valeriiz\\OneDrive - ORTEC Finance\\Desktop\\Thesis\\Code\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from Methods.variable_models import Model, key_word_dict\n",
    "from Methods.utils.priors import Uniform_prior, vectorize_matrix, vectorize_parameters, export_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.ones([10, 30, 30])\n",
    "B = np.zeros([30])+0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        ...,\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]],\n",
       "\n",
       "       [[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        ...,\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]],\n",
       "\n",
       "       [[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        ...,\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        ...,\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]],\n",
       "\n",
       "       [[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        ...,\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]],\n",
       "\n",
       "       [[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        ...,\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],\n",
       "        [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A-B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tails_external_sides=[500,500]\n",
    "number_of_paths=2000\n",
    "maturity_in_trend_steps=2\n",
    "starting_date = None #\"12/2010\"\n",
    "factors_from = \"FSA\"\n",
    "prior_name= \"uniform_prior\"\n",
    "number_of_lags=1\n",
    "\n",
    "fixed_lower = -1\n",
    "fixed_upper = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"C:\\\\Users\\\\valeriiz\\\\OneDrive - ORTEC Finance\\\\Desktop\\\\Thesis\\\\Data\\\\priors\\\\\"\n",
    "frequencies = [\"Trend\", \"Business cicle\", \"Monthly cicle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters= pd.read_excel(directory+prior_name+\"\\\\hyperparameters.xlsx\", sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals={}\n",
    "\n",
    "for frequency in frequencies:\n",
    "    upper = hyperparameters[frequency+\"_UB\"].to_numpy()[:, 1:]\n",
    "    lower = hyperparameters[frequency+\"_LB\"].to_numpy()[:, 1:]\n",
    "\n",
    "    K = upper.shape[0]\n",
    "\n",
    "    assert K == lower.shape[0]\n",
    "\n",
    "    upper = vectorize_matrix(upper[:,:1+K*number_of_lags]).reshape([K*(1+K*number_of_lags),1]).astype(float)\n",
    "    lower = vectorize_matrix(lower[:,:1+K*number_of_lags]).reshape([K*(1+K*number_of_lags),1]).astype(float)\n",
    "\n",
    "    upper = np.nan_to_num(upper, nan=fixed_upper)\n",
    "    lower = np.nan_to_num(lower, nan=fixed_lower)\n",
    "\n",
    "    intervals[frequency] = np.concatenate([lower, upper], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors ={}\n",
    "\n",
    "for frequency in frequencies:\n",
    "    prior = Uniform_prior(interval = intervals[frequency])\n",
    "\n",
    "    priors[frequency] = prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of variables 300 and forecast starts at 6/2024. Import took 4.5936808586120605.\n",
      "Elaborating data. (0.14461588859558105)\n",
      "Decomposing into 3 frequencies. (19.00502920150757)\n",
      "Elaborating data. (1.7409305572509766)\n",
      "Standardizing components. (0.14121031761169434)\n",
      "Reducing dimensionality...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valeriiz\\OneDrive - ORTEC Finance\\Desktop\\Thesis\\Code\\Methods\\utils\\utils_algorithm.py:179: UserWarning: Capping phase at 3.\n",
      "  warnings.warn(f\"Capping phase at {M}.\")\n",
      "C:\\Users\\valeriiz\\OneDrive - ORTEC Finance\\Desktop\\Thesis\\Code\\Methods\\utils\\utils_algorithm.py:179: UserWarning: Capping phase at 9.\n",
      "  warnings.warn(f\"Capping phase at {M}.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing dimensionality. (0.5093533992767334)\n"
     ]
    }
   ],
   "source": [
    "initial_start_time =time.time()\n",
    "df=pd.read_excel(r\"C:\\Users\\valeriiz\\OneDrive - ORTEC Finance\\Desktop\\Thesis\\Data\\Thesis data set - extended data.xlsx\", sheet_name=\"Final Data\")\n",
    "\n",
    "my_model=Model(df, start=starting_date)\n",
    "number_of_dimensions=df.index.to_list()[-1]+1\n",
    "print(f\"num of variables {number_of_dimensions} and forecast starts at {my_model.current_date}. Import took {time.time()-initial_start_time}.\")\n",
    "\n",
    "start_time =time.time()\n",
    "print(\"Elaborating data...\", end=\"\\r\")\n",
    "my_model.elaborate_data_new_1()\n",
    "print(f\"Elaborating data. ({time.time()-start_time})\")\n",
    "\n",
    "start_time =time.time()\n",
    "print(\"Decomposing into 3 frequencies...\", end=\"\\r\")\n",
    "my_model.decompose(tails_external_sides=tails_external_sides)\n",
    "print(f\"Decomposing into 3 frequencies. ({time.time()-start_time})\")\n",
    "\n",
    "start_time =time.time()\n",
    "print(\"Elaborating data...\", end=\"\\r\")\n",
    "my_model.elaborate_data_2()\n",
    "print(f\"Elaborating data. ({time.time()-start_time})\")\n",
    "\n",
    "start_time =time.time()\n",
    "print(\"Standardizing components...\", end=\"\\r\")\n",
    "my_model.standardize_decomposed_dict(\"Decomposed df LogReturns_F\")\n",
    "print(f\"Standardizing components. ({time.time()-start_time})\")\n",
    "\n",
    "start_time =time.time()\n",
    "factors = {}\n",
    "\n",
    "for f_and_t in my_model.frequency_names:\n",
    "    \n",
    "    names=pd.read_excel(f\"C:\\\\Users\\\\valeriiz\\\\OneDrive - ORTEC Finance\\\\Desktop\\\\Thesis\\\\Data\\\\Factors\\\\O_FSA_Factors_{f_and_t}.xlsx\", sheet_name=\"Factors\")[\"Factor\"].to_list()\n",
    "\n",
    "    factors[f_and_t]=my_model.decomposed_dict[\"DR_input\"][f_and_t].copy().rename(columns={\"Asset\": \"Factor\"}).drop(columns=[\"Datashape\"])\n",
    "\n",
    "    factors[f_and_t]=factors[f_and_t][factors[f_and_t][\"Factor\"].isin(names)]\n",
    "\n",
    "    factors[f_and_t] = factors[f_and_t].dropna(how=\"any\", axis=0)\n",
    "\n",
    "    factors[f_and_t]['Order'] = factors[f_and_t]['Factor'].map({name: i for i, name in enumerate(names)})\n",
    "\n",
    "    factors[f_and_t] = factors[f_and_t].sort_values('Order').drop('Order', axis=1)\n",
    "    \n",
    "    factors[f_and_t].reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Reducing dimensionality...\", end=\"\\r\")\n",
    "my_model.do_FSA(factors_pool=factors, max_expl=10, fixed_order=True)\n",
    "my_model.do_PCA()\n",
    "print(f\"Reducing dimensionality. ({time.time()-start_time})\")\n",
    "\n",
    "components = {\"Trend\": 3,\"Business cicle\": 9,\"Monthly cicle\": 10 }\n",
    "jumps = { \"Trend\": 96,\"Business cicle\": 12,\"Monthly cicle\": 1 }\n",
    "lags = { \"Trend\": 1,\"Business cicle\": 1,\"Monthly cicle\": 1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\valeriiz\\OneDrive - ORTEC Finance\\Desktop\\Thesis\\Data\\priors\\uniform_prior\\samples\\Trend\\FSA_lag_1_w_2000_to_None' already exists.\n",
      "Directory 'C:\\Users\\valeriiz\\OneDrive - ORTEC Finance\\Desktop\\Thesis\\Data\\priors\\uniform_prior\\samples\\Business cicle\\FSA_lag_1_w_2000_to_None' created.\n",
      "Directory 'C:\\Users\\valeriiz\\OneDrive - ORTEC Finance\\Desktop\\Thesis\\Data\\priors\\uniform_prior\\samples\\Monthly cicle\\FSA_lag_1_w_2000_to_None' created.\n"
     ]
    }
   ],
   "source": [
    "folder_name = f\"{factors_from}_lag_{number_of_lags}_w_{number_of_paths}_to_{starting_date}\"\n",
    "\n",
    "for frequency in frequencies:\n",
    "\n",
    "    data = my_model.decomposed_dict[factors_from][frequency][key_word_dict[factors_from]][:components[frequency]]\n",
    "\n",
    "    priors[frequency].aggregate_likelihood(data, number_of_lags= number_of_lags, jumps= jumps[frequency])\n",
    "\n",
    "    sample_dict = priors[frequency].sample(2000)\n",
    "\n",
    "    loc = directory + prior_name+\"\\\\samples\\\\\" + frequency + f\"\\\\{folder_name}\"\n",
    "\n",
    "    if not os.path.exists(loc):\n",
    "        os.mkdir(loc)\n",
    "        print(f\"Directory '{loc}' created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{loc}' already exists.\")\n",
    "\n",
    "    export_samples(loc, sample_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stan_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
